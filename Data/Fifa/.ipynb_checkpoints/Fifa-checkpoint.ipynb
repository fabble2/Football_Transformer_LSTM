{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from unidecode import  unidecode\n",
    "from urllib.parse import unquote\n",
    "import datetime \n",
    "#Ab dem Jahr 2016 gibt zu jedem Jahr wöchentliche Änderungen\n",
    "#Von 2010 bis 2015 gibt es nur vereinzelte Daten bzw. nur eine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "collect all urls for one season\n",
    "ouztput: list\n",
    "\"\"\"\n",
    "def collect_year():\n",
    "    liste=[]\n",
    "    for i in range(10,22):\n",
    "        link= \"https://www.fifaindex.com/de/teams/fifa\"+str(i)+\"/?league=19&order=desc\"\n",
    "        liste.append(link)\n",
    "    return liste\n",
    "#fifa_year=collect_year()\n",
    "\n",
    "\"\"\"\n",
    "input: month\n",
    "convert month name to number\n",
    "output: number\n",
    "\"\"\"\n",
    "def month(monat):\n",
    "    month=[\"Januar\",\"Februar\",\"März\",\"April\",\"Mai\",\"Juni\",\"Juli\",\"August\",\"September\",\"Oktober\",\"November\",\"Dezember\"]\n",
    "    nummer= month.index(monat)+1\n",
    "    if nummer<10:\n",
    "        nummer=\"0\"+str(nummer)\n",
    "    return nummer\n",
    "\n",
    "#Link der Saisons nehmen und alle Mannschaften pro Saison holen\n",
    "\"\"\"\n",
    "input: list of urls\n",
    "collect team names from all urls\n",
    "ouput: list of names\n",
    "\"\"\"\n",
    "def collect_teams(liste):\n",
    "    count= 10\n",
    "    teamcollection={}\n",
    "    for i in liste:\n",
    "        req = requests.get(i)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        teams= []\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            if str(a['href']).startswith(\"/de/team/\"):\n",
    "                #print(a['href'])\n",
    "                teams.append(a['href'])\n",
    "        teams=set(teams)\n",
    "        teamcollection.update({count:teams})\n",
    "        count=count+1\n",
    "    return teamcollection\n",
    "\n",
    "#team_dic= collect_teams(fifa_year)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input: dic\n",
    "Get player values and team values for each match day.\n",
    "Get the GES values for attack, midfield and defense from each side\n",
    "Fetch the values for each player\n",
    "output: pkl file\n",
    "\"\"\"\n",
    "def collect_datalinks(dic):\n",
    "    start= \"https://www.fifaindex.com\"\n",
    "    count=0\n",
    "    \n",
    "    for i in dic:# Schleife für Welches jahr\n",
    "        result={}\n",
    "        jahr=i\n",
    "        if int(jahr)>=16 and int(jahr)<=17:\n",
    "            for j in dic[i]:# Schleife für Mannschaft und deren GES pro Spiel\n",
    "\n",
    "                #Links pro \"Spiel\" sammeln\n",
    "                link= start+j\n",
    "                mannschaft=j.split(\"/\")[-3].split(\"-\")\n",
    "                team=\"\"\n",
    "                for g in mannschaft:\n",
    "                    team=team+\" \"+unidecode(unquote(g))\n",
    "                key=team.strip()\n",
    "                req= requests.get(link)\n",
    "                #print(type(req))\n",
    "                soup= BeautifulSoup(req.text, \"html.parser\")\n",
    "                #print(req.text)\n",
    "                dropdowns=soup.find_all(\"li\",\"breadcrumb-item dropdown\")\n",
    "                team_links=[]\n",
    "                datum=[]\n",
    "                for x in dropdowns[1].find_all(\"a\",\"dropdown-item\"):\n",
    "                    datum.append(x.getText())\n",
    "                    team_links.append(x.get('href'))\n",
    "\n",
    "                #Aus jedem Link Bewertungen von Anfriff, Mittelfeld, Defensive holen\n",
    "                #Reihenfolge: Angriff, Mittelfeld, Defensive\n",
    "                #für 2010-2018: Aufbauspiel,Chancenverarbeitung, Defensive\n",
    "                #für 2019-2021: Defensivstil, Offensivstil\n",
    "                werte_pro_Spiel=[]\n",
    "                werte_ges=[]\n",
    "                for h in team_links:\n",
    "                    url=start+h\n",
    "                    #print(url)\n",
    "                    teamname= h.split(\"/\")[-3].replace(\"-\",\" \")\n",
    "                    req= requests.get(url)\n",
    "                    soup= BeautifulSoup(req.text,\"html.parser\")\n",
    "                    werte_pro_Spiel=[]\n",
    "                \n",
    "                    for i in soup.find_all(\"table\",\"table table-players table-striped\"):\n",
    "                        #print(i)\n",
    "                        #Namen der Spieler\n",
    "                        names=[]\n",
    "                        for j in (i.find_all(\"a\",{\"class\":\"link-player\"})):\n",
    "                            if j.getText() != \"\":\n",
    "                                names.append(j.getText())\n",
    "                        #Werte der Spieler, GES und POT, nur GES wichtig\n",
    "                        ges=[]\n",
    "                        for j in (i.find_all(\"span\",{\"class\":[\"badge badge-dark rating r1\",\"badge badge-dark rating r2\",\"badge badge-dark rating r3\",\"badge badge-dark rating r4\"]})):\n",
    "                            if j.getText() != \"\":\n",
    "                                ges.append(j.getText())\n",
    "                        del ges[1::2]\n",
    "                        \n",
    "                        for i in range(0,len(ges)):\n",
    "                            gesamt= names[i]+ \" \"+ges[i]\n",
    "                            werte_pro_Spiel.append(gesamt)\n",
    "                            \n",
    "                        break\n",
    "                    \n",
    "                    werte_ges.append(werte_pro_Spiel)\n",
    "                #print(werte_ges)\n",
    "                spieltage_anzahl=[]\n",
    "                for i in range(0,len(werte_ges)):\n",
    "                    spieltag=34-i\n",
    "                    spieltage_anzahl.append(spieltag)\n",
    "                datum_zahl=[]\n",
    "                for i in datum:\n",
    "                    split= i.split(\" \")\n",
    "                    tag=split[0].split(\".\")[0]\n",
    "                    if int(tag)<10:\n",
    "                        tag=\"0\"+tag\n",
    "                    monat=month(split[1])\n",
    "                    neu=str(tag)+\".\"+str(monat)\n",
    "                    datum_zahl.append(neu)\n",
    "                \n",
    "                #Ab 2016 kommen erst mehere Aktualisierungen pro Saison hinzu\n",
    "                #2010-2015: Reicht eine Mannschaft\n",
    "                #Ab 2016: Datum vergleichen\n",
    "                \n",
    "                #Datums verkürzen auf Spielzeit(wurde nach Spielzeit noch aktualisiert)\n",
    "                \n",
    "                check=0#für Jahr bis 2016\n",
    "                for i in datum_zahl:\n",
    "                    if i.endswith(\"06\"):\n",
    "                        #print(datum_zahl.index(i))\n",
    "                        delete_index=datum_zahl.index(i)\n",
    "                 #       check=1\n",
    "                        break\n",
    "                #if check==1:\n",
    "                \n",
    "                del werte_ges[0:delete_index]\n",
    "                del datum_zahl[0:delete_index]\n",
    "                \n",
    "                \n",
    "                spieldatum= date(jahr)\n",
    "                index_liste=[]\n",
    "                for i in range(34,0,-1):\n",
    "                    #print(i)\n",
    "                    gamedate= spieldatum[i]\n",
    "                    gamedate= gamedate.split(\".\")\n",
    "                    \n",
    "                    d1 = datetime.datetime(1000, int(gamedate[1]), int(gamedate[0]))\n",
    "                    #print(d1)\n",
    "                    #print(\"----\")\n",
    "                    for j in datum_zahl:\n",
    "                        gamedate2= j.split(\".\")\n",
    "                        if int(gamedate[1])>=8 and int(gamedate2[1])<=7:\n",
    "                            continue\n",
    "                        d2= datetime.datetime(1000,int(gamedate2[1]),int(gamedate2[0]))\n",
    "                        #print(d2)\n",
    "                        if d2<d1:\n",
    "                            richtiges_datum=str(d2).split(\" \")[0].split(\"-\")[1:]\n",
    "                            indexname= str(richtiges_datum[1])+\".\"+str(richtiges_datum[0])\n",
    "                            index_liste.append(datum_zahl.index(indexname))\n",
    "                            #print(\"GEFUNDEN\",d1,indexname,datum_zahl.index(indexname))\n",
    "                            break\n",
    "                        if j== datum_zahl[len(datum_zahl)-1]:\n",
    "                            indexname= j\n",
    "                            index_liste.append(datum_zahl.index(indexname))\n",
    "                            #print(\"GEFUNDEN\",d1,indexname,datum_zahl.index(indexname))\n",
    "                            break\n",
    "                werte=[]\n",
    "                for i in index_liste:\n",
    "                    werte.append(werte_ges[i])\n",
    "                result.update({teamname:werte})\n",
    "            data= pd.DataFrame.from_dict(result)\n",
    "            filename= \"Fifa\"+str(jahr)+\".pkl\"\n",
    "            file = open(filename, 'wb')\n",
    "            pickle.dump(data,file)\n",
    "            file.close()   \n",
    "        \n",
    "#collect_datalinks(team_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input: year\n",
    "Getting the date of the match via kicker.\n",
    "You have too many updates in the last years from the sport\n",
    "So you have to pick the right teams for the match day\n",
    "ouput: dic\n",
    "\"\"\"\n",
    "\n",
    "def date(jahr):\n",
    "    #Erstellen des Links\n",
    "    if jahr==10:\n",
    "        jahr2=\"09\"\n",
    "    else:\n",
    "        jahr2= int(jahr)-1\n",
    "    link_ende= \"20\"+str(jahr2)+\"-\"+str(jahr)\n",
    "    link= \"https://www.kicker.de/bundesliga/spieltag/\"+link_ende\n",
    "    \n",
    "    #Auf der Seite werden alle Spieltage mit Datum gelistet, diese nun holen\n",
    "    req= requests.get(link)\n",
    "    soup= BeautifulSoup(req.text, \"html.parser\")\n",
    "    dropdown=soup.find_all(\"select\",\"kick__head-dropdown__select\")\n",
    "    spieltag=dropdown[1]\n",
    "    dic={}\n",
    "    for x in spieltag.find_all(\"option\"):\n",
    "        if(str(x.getText().strip()).startswith(\"Alle\")):\n",
    "            continue\n",
    "        nummer= x.getText().strip().split(\".\")[0]\n",
    "        datum=x.getText().strip().split(\"(\")[1].split(\"-\")[0].strip()[:-1]\n",
    "        dic.update({int(nummer):datum})\n",
    "    return dic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "collect all urls for one season\n",
    "ouztput: list\n",
    "\"\"\"\n",
    "def collect_year():\n",
    "    liste=[]\n",
    "    for i in range(10,22):\n",
    "        link= \"https://www.fifaindex.com/de/teams/fifa\"+str(i)+\"/?league=19&order=desc\"\n",
    "        liste.append(link)\n",
    "    return liste\n",
    "#fifa_year=collect_year()\n",
    "\n",
    "\"\"\"\n",
    "input: month\n",
    "convert month name to number\n",
    "output: number\n",
    "\"\"\"\n",
    "def month(monat):\n",
    "    month=[\"Januar\",\"Februar\",\"März\",\"April\",\"Mai\",\"Juni\",\"Juli\",\"August\",\"September\",\"Oktober\",\"November\",\"Dezember\"]\n",
    "    nummer= month.index(monat)+1\n",
    "    if nummer<10:\n",
    "        nummer=\"0\"+str(nummer)\n",
    "    return nummer\n",
    "\n",
    "#Link der Saisons nehmen und alle Mannschaften pro Saison holen\n",
    "\"\"\"\n",
    "input: list of urls\n",
    "collect team names from all urls\n",
    "ouput: list of names\n",
    "\"\"\"\n",
    "def collect_teams(liste):\n",
    "    count= 10\n",
    "    teamcollection={}\n",
    "    for i in liste:\n",
    "        req = requests.get(i)\n",
    "        soup = BeautifulSoup(req.text, \"html.parser\")\n",
    "        teams= []\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            if str(a['href']).startswith(\"/de/team/\"):\n",
    "                #print(a['href'])\n",
    "                teams.append(a['href'])\n",
    "        teams=set(teams)\n",
    "        teamcollection.update({count:teams})\n",
    "        count=count+1\n",
    "    return teamcollection\n",
    "\n",
    "#team_dic= collect_teams(fifa_year)\n",
    "\n",
    "\"\"\"\n",
    "input: dic\n",
    "Get player values and team values for each match day.\n",
    "Get the GES values for attack, midfield and defense from each side\n",
    "Fetch the values for each player\n",
    "output: pkl file\n",
    "\"\"\"\n",
    "def collect_datalinks(dic):\n",
    "    start= \"https://www.fifaindex.com\"\n",
    "    count=0\n",
    "    \n",
    "    for i in dic:# Schleife für Welches jahr\n",
    "        result={}\n",
    "        jahr=i\n",
    "        if int(jahr)<16:\n",
    "            for j in dic[i]:# Schleife für Mannschaft und deren GES pro Spiel\n",
    "\n",
    "                #Links pro \"Spiel\" sammeln\n",
    "                link= start+j\n",
    "                mannschaft=j.split(\"/\")[-3].split(\"-\")\n",
    "                team=\"\"\n",
    "                for g in mannschaft:\n",
    "                    team=team+\" \"+unidecode(unquote(g))\n",
    "                key=team.strip()\n",
    "                req= requests.get(link)\n",
    "                #print(type(req))\n",
    "                soup= BeautifulSoup(req.text, \"html.parser\")\n",
    "                #print(req.text)\n",
    "                dropdowns=soup.find_all(\"li\",\"breadcrumb-item dropdown\")\n",
    "                team_links=[]\n",
    "                datum=[]\n",
    "                for x in dropdowns[1].find_all(\"a\",\"dropdown-item\"):\n",
    "                    datum.append(x.getText())\n",
    "                    team_links.append(x.get('href'))\n",
    "\n",
    "                #Aus jedem Link Bewertungen von Anfriff, Mittelfeld, Defensive holen\n",
    "                #Reihenfolge: Angriff, Mittelfeld, Defensive\n",
    "                #für 2010-2018: Aufbauspiel,Chancenverarbeitung, Defensive\n",
    "                #für 2019-2021: Defensivstil, Offensivstil\n",
    "                werte_ges=[]\n",
    "                werte_pro_spiel=[]\n",
    "                #Alle Werte aus den teamlinks holen\n",
    "                for h in team_links:\n",
    "                    url=start+h\n",
    "                    teamname= h.split(\"/\")[-3].replace(\"-\",\" \")\n",
    "                    req= requests.get(url)\n",
    "                    soup= BeautifulSoup(req.text,\"html.parser\")\n",
    "                    print(url)\n",
    "                    ges=[]\n",
    "                    for i in soup.find_all(\"li\",{\"class\":\"list-group-item\"}):\n",
    "                        \n",
    "                        #Werte der Spieler, GES und POT, nur GES wichtig\n",
    "                        \n",
    "                        for j in (i.find_all(\"span\",{\"class\":[\"badge badge-dark rating r1\",\"badge badge-dark rating r2\",\"badge badge-dark rating r3\",\"badge badge-dark rating r4\"]})):\n",
    "                            \n",
    "                            if j.getText() != \"\":\n",
    "                                ges.append(j.getText())\n",
    "                    \n",
    "                    if ges:\n",
    "                        werte_pro_spiel.append(ges)        \n",
    "                #print(len(werte_pro_spiel), len(datum))\n",
    "                datum_zahl=[]\n",
    "                for i in datum:\n",
    "                    split= i.split(\" \")\n",
    "                    tag=split[0].split(\".\")[0]\n",
    "                    if int(tag)<10:\n",
    "                        tag=\"0\"+tag\n",
    "                    monat=month(split[1])\n",
    "                    neu=str(tag)+\".\"+str(monat)\n",
    "                    datum_zahl.append(neu)\n",
    "                check=0    \n",
    "                for i in datum_zahl:\n",
    "                    if i.endswith(\"06\"):\n",
    "                        #print(datum_zahl.index(i))\n",
    "                        delete_index=datum_zahl.index(i)\n",
    "                        check=1\n",
    "                        break\n",
    "                if check==1:\n",
    "                    del werte_pro_spiel[0:delete_index]\n",
    "                    del datum_zahl[0:delete_index]\n",
    "                #print(len(werte_pro_spiel), len(datum_zahl))\n",
    "                \n",
    "                spieldatum= date(jahr)\n",
    "                index_liste=[]\n",
    "                for i in range(34,0,-1):\n",
    "                    #print(i)\n",
    "                    gamedate= spieldatum[i]\n",
    "                    gamedate= gamedate.split(\".\")\n",
    "                    \n",
    "                    d1 = datetime.datetime(1000, int(gamedate[1]), int(gamedate[0]))\n",
    "                    #print(d1)\n",
    "                    #print(\"----\")\n",
    "                    for j in datum_zahl:\n",
    "                        gamedate2= j.split(\".\")\n",
    "                        if int(gamedate[1])>=8 and int(gamedate2[1])<=7:\n",
    "                            continue\n",
    "                        d2= datetime.datetime(1000,int(gamedate2[1]),int(gamedate2[0]))\n",
    "                        #print(d2)\n",
    "                        if d2<d1:\n",
    "                            richtiges_datum=str(d2).split(\" \")[0].split(\"-\")[1:]\n",
    "                            indexname= str(richtiges_datum[1])+\".\"+str(richtiges_datum[0])\n",
    "                            index_liste.append(datum_zahl.index(indexname))\n",
    "                            #print(\"GEFUNDEN\",d1,indexname,datum_zahl.index(indexname))\n",
    "                            break\n",
    "                        if j== datum_zahl[len(datum_zahl)-1]:\n",
    "                            indexname= j\n",
    "                            index_liste.append(datum_zahl.index(indexname))\n",
    "                            #print(\"GEFUNDEN\",d1,indexname,datum_zahl.index(indexname))\n",
    "                            break\n",
    "                print(len(werte_pro_spiel), index_liste)\n",
    "                werte=[]\n",
    "                for i in index_liste:\n",
    "                    if i >(len(werte_pro_spiel)-1):\n",
    "                        i=int(len(werte_pro_spiel)-1)\n",
    "                        \n",
    "                    werte.append(werte_pro_spiel[i])\n",
    "                result.update({teamname:werte})\n",
    "                \n",
    "            data= pd.DataFrame.from_dict(result)\n",
    "            filename= \"FifaGes\"+str(jahr)+\".pkl\"\n",
    "            file = open(filename, 'wb')\n",
    "            pickle.dump(data,file)\n",
    "            file.close()\n",
    "        \n",
    "#collect_datalinks(team_dic)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
