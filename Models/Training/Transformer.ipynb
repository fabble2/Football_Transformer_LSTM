{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from difflib import SequenceMatcher\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from itertools import chain \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------DATENVERARBEITUNG---------------------------------------------\n",
    "\"\"\"\n",
    "input: matchday number to be predicted\n",
    "get the data from the match from each team\n",
    "get training and test data\n",
    "output: training, test data, teams\n",
    "\"\"\"\n",
    "def getdataTraining(nummer):\n",
    "    data=pd.read_pickle(\"Daten161718.pkl\")\n",
    "    matrix= data[0]\n",
    "    mannschaften= data[1]\n",
    "    schleifennummer= nummer-1\n",
    "    training=[]\n",
    "    test=[]\n",
    "    \n",
    "    #Alle Spiele vom 1. Spieltag bis zum x. Spieltag holen\n",
    "    #in Trainings und Testdaten zuordnen\n",
    "    for mannschaft in range(0,20):\n",
    "        for spieltag in range(0,schleifennummer):\n",
    "            training.append(matrix[mannschaft][spieltag])\n",
    "        test.append(matrix[mannschaft][nummer-1])\n",
    "    \n",
    "    #Spiele der Mannschaften zuordnen, ersten x Spiele gehören Team 1 usw.\n",
    "    training_dic={}\n",
    "    for i in range(0,20):\n",
    "        training_dic[i]= training[(nummer-1)*i:(nummer-1)*(i+1)]\n",
    "    \n",
    "    return training_dic,test,mannschaften\n",
    "\n",
    "\"\"\"\n",
    "get teams from training set\n",
    "output: teams\n",
    "\"\"\"\n",
    "def get_mannschaftenTraining():\n",
    "    data=pd.read_pickle(\"Daten161718.pkl\")\n",
    "    mannschaften= data[1]\n",
    "    return mannschaften\n",
    "\n",
    "\"\"\"\n",
    "input number\n",
    "get data of seasons\n",
    "output: traning test data, teams\n",
    "\"\"\"\n",
    "def getdata(nummer):\n",
    "    data=pd.read_pickle(\"Daten2019.pkl\")\n",
    "    matrix= data[0]\n",
    "    mannschaften= data[2]\n",
    "    schleifennummer= nummer-1\n",
    "    training=[]\n",
    "    test=[]\n",
    "    \n",
    "    #Alle Spiele vom 1. Spieltag bis zum x. Spieltag holen\n",
    "    #in Trainings und Testdaten zuordnen\n",
    "    for mannschaft in range(0,18):\n",
    "        for spieltag in range(0,schleifennummer):\n",
    "            training.append(matrix[mannschaft][spieltag])\n",
    "        test.append(matrix[mannschaft][nummer-1])\n",
    "    \n",
    "    #Spiele der Mannschaften zuordnen, ersten x Spiele gehören Team 1 usw.\n",
    "    training_dic={}\n",
    "    for i in range(0,18):\n",
    "        training_dic[i]= training[(nummer-1)*i:(nummer-1)*(i+1)]\n",
    "    \n",
    "    return training_dic,test,mannschaften\n",
    "\n",
    "\"\"\"\n",
    "input: team1\n",
    "get names of teams (opponent)\n",
    "output: teams\n",
    "\"\"\"\n",
    "def get_mannschaften(name):\n",
    "    data=pd.read_pickle(name)\n",
    "    mannschaften= data[2]\n",
    "    return mannschaften\n",
    "\n",
    "\"\"\"\n",
    "input match day\n",
    "Auxiliary method to determine the number of matches and the time size.\n",
    "Input: Desired match day, which should be predicted\n",
    "Wanted to consider 5 games out of 5 games.\n",
    "if this is not possible, less games will be considered for one game\n",
    "worst-case: no 5 games can be considered and therefore no 5 games, but 2 and 1\n",
    "output: time_size, number\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def size_of_time(spieltag):\n",
    "    \n",
    "    if spieltag >=12:\n",
    "        time_size= 5\n",
    "        anzahl= spieltag-6\n",
    "    else:\n",
    "        #spieltag=spieltag-1\n",
    "        differenz1= spieltag-6\n",
    "        differenz2= spieltag-5\n",
    "        if differenz1 >=3: #Spieltag 9,10,11\n",
    "            time_size= differenz1\n",
    "            anzahl=5\n",
    "        elif differenz2 ==3: #Spieltag 8\n",
    "            time_size= differenz2\n",
    "            anzahl=4\n",
    "        elif spieltag-4==3:# Spieltag 7\n",
    "            time_size= 3\n",
    "            anzahl= 3\n",
    "        elif spieltag-3==3: # Spieltag 6\n",
    "            time_size= 2\n",
    "            anzahl= 3\n",
    "        elif spieltag-2==3: #Spieltag 5\n",
    "            time_size= 3\n",
    "            anzahl= 3\n",
    "        elif spieltag-1==3: # Spieltag 4\n",
    "            time_size= 2\n",
    "            anzahl= 2\n",
    "        elif spieltag >2: #usw.\n",
    "            time_size=1\n",
    "            anzahl=1\n",
    "        else:\n",
    "            time_size=0\n",
    "            anzahl=0\n",
    "    return time_size,anzahl\n",
    "\n",
    "\"\"\"\n",
    "input; data, team\n",
    "filter the statistics of the respective team\n",
    "output: List of statistics from the games\n",
    "\"\"\"\n",
    "def get_statistik(data, team):\n",
    "    liste=[]\n",
    "    \n",
    "    for i in data:\n",
    "        teams= i[-2:]\n",
    "        werte= i[:-2]\n",
    "        if teams[0]==team:\n",
    "            liste.append(werte[19:32])\n",
    "        else:\n",
    "            liste.append(werte[51:64])\n",
    "    return liste\n",
    "\n",
    "\"\"\"\n",
    "input: team, list of teams\n",
    "Similarity search of the teams\n",
    "ouput: right team name\n",
    "\"\"\"\n",
    "def similar(mannschaft, liste): \n",
    "    wert=0\n",
    "    currentteam=\"\"\n",
    "    \n",
    "    for team in liste:\n",
    "        similarity= SequenceMatcher(None, mannschaft, team).ratio()\n",
    "        #print(team, similarity)\n",
    "        if wert < similarity:\n",
    "            wert= similarity\n",
    "            currentteam= team\n",
    "            \n",
    "    return currentteam\n",
    "\n",
    "\"\"\"\n",
    "input: data, lis of team, team, matchday number, promoted team, relegated team\n",
    "Reduction of the data\n",
    "If there is a promoted team at the queried game\n",
    "you can't look at the previous season, because there is only one team there\n",
    "So --> remove data of the previous season\n",
    "If there is a relegated team at the queried game\n",
    "--> Error message\n",
    "This is done for 3 seasons(so 2 promoted/relegated)\n",
    "output: Data, new game day(instead of 40, 40-34=6).\n",
    "\"\"\"\n",
    "def data_auf_absteiger(data,mannschaftsliste,mannschaft,spieltag,absteiger,aufsteiger):\n",
    "\n",
    "    #Indices der spielenenden Mannschaften herausfinden\n",
    "    current_team1=similar(mannschaft[0],mannschaftsliste)\n",
    "    index1= mannschaftsliste.index(current_team1)\n",
    "    \n",
    "    current_team2=similar(mannschaft[1],mannschaftsliste)\n",
    "    index2= mannschaftsliste.index(current_team2)\n",
    "    \n",
    "    #Zusammenführung der Auf- bzw. Absteiger in einer Liste für Abfrage\n",
    "    auf= list(chain.from_iterable(list(aufsteiger.values())))\n",
    "    ab= list(chain.from_iterable(list(absteiger.values())))\n",
    "    \n",
    "    if spieltag >34 and (index1 in auf or index2 in auf or index1 in ab or index2 in ab):\n",
    "        \n",
    "        #Saison 2\n",
    "        if spieltag <69:\n",
    "            #Auf-/Absteiger von Saison 3 entfernen\n",
    "            del absteiger[1]\n",
    "            del aufsteiger[2]\n",
    "            #Schauen ob Mannschaft Auf-/Absteiger ist, zweite Saison\n",
    "            \n",
    "            # Wenn sich um Absteiger handelt, ist dieser nicht in aktueller Saison --> Fehler\n",
    "            for key,values in absteiger.items():\n",
    "                if index1 in values or index2 in values:\n",
    "                    return \"KEY ERROR\",\"\"\n",
    "            #Wenn sich um Aufsteiger handelt \n",
    "            #--> Saison 1 aus Daten nehmen und Spieltag aktualisiern\n",
    "            for key,values in aufsteiger.items():\n",
    "                if index1 in values or index2 in values:\n",
    "                    for key, values in data.items():\n",
    "                        data.update({key:values[34:]})\n",
    "                    return data, spieltag-34\n",
    "                else:\n",
    "                    return data, spieltag\n",
    "        #Saison 3\n",
    "        if spieltag >=69:\n",
    "            #Absteiger entfernen\n",
    "            del absteiger[0]\n",
    "            \n",
    "            # Wenn sich um Absteiger handelt, ist dieser nicht in aktueller Saison --> Fehler\n",
    "            for key,values in absteiger.items():\n",
    "                if index1 in values or index2 in values:\n",
    "                    return \"KEY ERROR\",\"\"\n",
    "            #Wenn sich um Aufsteiger handelt \n",
    "            #--> Ab Saison 1 bzw. ab Saison 2 aus Daten nehmen und Spieltag aktualisiern\n",
    "            for key,values in aufsteiger.items():\n",
    "                if index1 in values or index2 in values:\n",
    "                    if key==1: #Aufsteiger von Sasion2\n",
    "                        for key, values in data.items():\n",
    "                            data.update({key:values[68:]})\n",
    "                        return data, spieltag-68\n",
    "                    else: #Aufsteiger von Saison3\n",
    "                        for key, values in data.items():\n",
    "                            data.update({key:values[68:]})\n",
    "                        return data, spieltag-68\n",
    "    else:# Fall für Saison1 ==> keine Reduzierung notwendig\n",
    "        return data, spieltag\n",
    "    \n",
    "\"\"\"\n",
    "input: data, team, list of team\n",
    "Find out the opponent of the passed team\n",
    "Go through data and find team. There is also the opponentID\n",
    "output: Name of opponent and location(is team home or visiting team).\n",
    "\"\"\"\n",
    "def getgegner(data,teamname,mannschaftsliste):\n",
    "    current_team=similar(teamname,mannschaftsliste)\n",
    "    key= mannschaftsliste.index(current_team)\n",
    "    \n",
    "    #Gegner finden\n",
    "    for i in data:\n",
    "        teams= i[-2:]\n",
    "        if key in teams:\n",
    "            current_teams= teams\n",
    "            break\n",
    "    #Heim oder Auswärtsmannschaft\n",
    "    if list(current_teams).index(key)==0:\n",
    "        ort= \"home\"\n",
    "    else:\n",
    "        ort= \"away\"\n",
    "    \n",
    "    #Name des Gegner bekommen\n",
    "    gegner= current_teams[current_teams!=key][0]\n",
    "    gegnername= mannschaftsliste[int(gegner)]\n",
    "    return gegnername,ort\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#--------------------------TIMESEQUENZEN/AUXDATA TRAINING---------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input: data, list of team, team, match day\n",
    "Create time sequences\n",
    "In the best case the last 5 game statistics are considered per game\n",
    "How many are looked at is calculated with size_of_time\n",
    "Now get x statistics from the team and its opponents\n",
    "Save them in a list and consider the next game day\n",
    "output: List of TimeSequences, size of each TimeSequence, team key.\n",
    "\"\"\"\n",
    "def time_sequence(data,mannschaftsliste,mannschaft,spieltag):\n",
    "    time_size, anzahl= size_of_time(spieltag)\n",
    "    time_series={}\n",
    "    list_of_game_series=[]\n",
    "    grenze= spieltag-1\n",
    "    \n",
    "    #Mannschaftnummer finden\n",
    "    current_team=similar(mannschaft,mannschaftsliste)\n",
    "    #TimeSequenzen erstellen\n",
    "    for key,values in data.items():\n",
    "        if key!= mannschaftsliste.index(current_team):\n",
    "            continue\n",
    "        else:\n",
    "            for i in range(time_size,grenze): #Spiele die betrachtet werden\n",
    "                teams= values[i][-2:]\n",
    "                start_gegner= i-time_size\n",
    "                if teams[0]==key:\n",
    "                    #\"Rohe\" Daten holen\n",
    "                    gegner_statistik= data[teams[1]][start_gegner:i]\n",
    "                    team_statistik= data[teams[0]][start_gegner:i]\n",
    "                    #Filterung der Statistiken\n",
    "                    team_statistik= get_statistik(team_statistik,teams[0])\n",
    "                    gegner_statistik= get_statistik(gegner_statistik,teams[1])\n",
    "                    #Zusammenführung\n",
    "                    game_series= np.concatenate((team_statistik, gegner_statistik), axis=1)\n",
    "                else:\n",
    "                    #\"Rohe\" Daten holen\n",
    "                    gegner_statistik= data[teams[0]][start_gegner:i]\n",
    "                    team_statistik= data[teams[1]][start_gegner:i]              \n",
    "                    #Filterung der Statistiken\n",
    "                    team_statistik= get_statistik(team_statistik,teams[1])\n",
    "                    gegner_statistik= get_statistik(gegner_statistik,teams[0])\n",
    "                    #Zusammenführung\n",
    "                    game_series= np.concatenate((gegner_statistik, team_statistik), axis=1)\n",
    "                list_of_game_series.append(game_series)\n",
    "                \n",
    "    mannschaftskey= mannschaftsliste.index(current_team)\n",
    "    return np.array(list_of_game_series), mannschaftskey, time_size\n",
    "\n",
    "\"\"\"\n",
    "input: data, key of team, matchday\n",
    "Create auxiliary data, i.e. table, team, player values, betting odds.\n",
    "extract output for these matches as well\n",
    "se #size of time to find considered games\n",
    "create list for aux_data and output\n",
    "output: list of aux data and list of output values\n",
    "\"\"\"\n",
    "def auxilary_data(data,mannschaftskey,spieltag):\n",
    "    time_size, anzahl= size_of_time(spieltag)\n",
    "    aux_data={}\n",
    "    out_data={}\n",
    "    grenze= spieltag-1\n",
    "    \n",
    "    for key,values in data.items():\n",
    "        list_of_game_series=[]\n",
    "        list_of_outputs=[]\n",
    "        if key!= mannschaftskey:\n",
    "            continue\n",
    "        else:\n",
    "            for i in range(time_size,grenze):\n",
    "                teams= values[i][-2:]\n",
    "                start_gegner= i-time_size\n",
    "                #Aux_Data und Output holen\n",
    "                home_team= values[i][:19]\n",
    "                away_team= values[i][32:51]\n",
    "                odds= values[i][64:67]\n",
    "                output= values[i][67:70]\n",
    "                game_data= np.concatenate((home_team,away_team,odds))\n",
    "                #Speichern in Listen\n",
    "                list_of_outputs.append(output)\n",
    "                list_of_game_series.append(game_data)\n",
    "            #Separierung der Mannschaften durch dictionary\n",
    "            aux_data[key]=list_of_game_series\n",
    "            out_data[key]=list_of_outputs\n",
    "            \n",
    "    return list(aux_data.values()),list(out_data.values())\n",
    "\n",
    "\"\"\"        \n",
    "input: outputs\n",
    "convert output into single values, [1,0,0]=1,[0,1,0]=0,[0,0,1]=2\n",
    "output: array with single values instead of single lists\n",
    "\"\"\" \n",
    "def out_data(outputs):\n",
    "    output=[]\n",
    "    \n",
    "    for i in outputs:\n",
    "        if i[0]==1:\n",
    "            output.append(0)\n",
    "        elif i[1]==1:\n",
    "            output.append(1)\n",
    "        else:\n",
    "            output.append(2)\n",
    "    return np.array(output)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------TIMESEQUENZEN/AUXDATA FÜR DEN TEST----------------------------------\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "input: trainings data, test data, team, match day\n",
    "Create TimeSequence for the test data\n",
    "Difference one looks only at the one game\n",
    "First find out home and away team\n",
    "Then create the TimeSequence for both teams\n",
    "loop does not run, because the game is twice in the list\n",
    "output: array with time sequences\n",
    "\"\"\"\n",
    "def time_sequence_test(data_training,data_test,team,spieltag):\n",
    "\n",
    "    time_size, anzahl= size_of_time(spieltag)\n",
    "    liste=[]\n",
    "    \n",
    "    #Herausfindeen ob Team Heim oder Auswärtsmannschaft ist\n",
    "    for spiele in data_test:\n",
    "        mannschaften= spiele[-2:]\n",
    "        if team in mannschaften:\n",
    "            if mannschaften[0]==team:\n",
    "                gegner= [mannschaften[1],\"away\"]\n",
    "            else:\n",
    "                gegner= [mannschaften[0],\"home\"]\n",
    "            break\n",
    "    \n",
    "    #TimeSequenz erstellen\n",
    "    for key,values in data_training.items():\n",
    "        if key!= team:\n",
    "            continue\n",
    "        else:\n",
    "\n",
    "            gegner_statistik= data_training[gegner[0]][-time_size:]\n",
    "            team_statistik= data_training[team][-time_size:]\n",
    "            #Filterung der Statistiken\n",
    "            team_statistik= get_statistik(team_statistik,team)\n",
    "            gegner_statistik= get_statistik(gegner_statistik,gegner[0])\n",
    "            #Zusammenführung und Reihenfolge beachten\n",
    "            if gegner[1]==\"away\":\n",
    "                game_series= np.concatenate((team_statistik, gegner_statistik), axis=1)\n",
    "            else:\n",
    "                game_series= np.concatenate((gegner_statistik, team_statistik), axis=1)\n",
    "            liste.append(game_series)\n",
    "            return np.array(liste)\n",
    "\n",
    "\"\"\"\n",
    "input: test data, team\n",
    "Fetch auxilary data for test\n",
    "Simply fetch these values for a game\n",
    "loop does not run because the game is in the list twice\n",
    "output: List of Aux_Data and list of playing teams.\n",
    "\"\"\"\n",
    "def auxilary_data_test(data_test,team):\n",
    "    liste=[]\n",
    "    for spiele in data_test:\n",
    "        mannschaften= spiele[-2:] #Mannschaften bekommen\n",
    "        if team in mannschaften: #Mannschaft finden\n",
    "            #Werte holen\n",
    "            home_team= spiele[:19]\n",
    "            away_team= spiele[32:51]\n",
    "            odds= spiele[64:67]\n",
    "            output= spiele[67:70]\n",
    "            game_data= np.concatenate((home_team,away_team,odds))\n",
    "            liste.append(game_data)\n",
    "            return liste, mannschaften, output\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#---------------------------------SPEZIALFÄLLE-----------------------------------------------\n",
    "\n",
    "\"\"\"\n",
    "input: data, test data, list of team, team\n",
    "get all data, so TimeSequence, Aux_data, Output for the 2.GAME DAY\n",
    "is a special case because you can't build a real TimeSequence because you know only one game #from past\n",
    "knowing from the past\n",
    "output: All data: (TimeSequence, Aux, Output)*2 (for both teams), Key from team\n",
    "\"\"\"\n",
    "def getspieltag2(data,test,mannschaftsliste,mannschaft):\n",
    "    current_team=similar(mannschaft,mannschaftsliste)\n",
    "    liste_time_series=[]\n",
    "    liste_aux=[]\n",
    "    liste_time_series_a=[]\n",
    "    liste_aux_a=[]\n",
    "    output=[]\n",
    "    output_a=[]\n",
    "    \n",
    "    #Mannschaften holen\n",
    "    for spiele in test:\n",
    "        mannschaften=spiele[-2:]\n",
    "        if mannschaftsliste.index(current_team) in mannschaften:\n",
    "            current_teams= mannschaften\n",
    "            break\n",
    "    \n",
    "    #Daten für Mannschaften holen\n",
    "    for key,values in data.items():\n",
    "        for i in current_teams:\n",
    "            if key==i and i == current_teams[0]:\n",
    "                #TimeSequenz\n",
    "                liste_time_series.append(values[0][19:32])\n",
    "                liste_time_series.append(values[0][51:64])\n",
    "                liste_aux.append(values[0][:19])\n",
    "                liste_aux.append(values[0][32:51])\n",
    "                liste_aux.append(values[0][64:67])\n",
    "                output.append(values[0][67:70])\n",
    "            if key==i and i == current_teams[1]:\n",
    "                liste_time_series_a.append(values[0][19:32])\n",
    "                liste_time_series_a.append(values[0][51:64])\n",
    "                liste_aux_a.append(values[0][:19])\n",
    "                liste_aux_a.append(values[0][32:51])\n",
    "                liste_aux_a.append(values[0][64:67])\n",
    "                output_a.append(values[0][67:70])\n",
    "                \n",
    "    liste_time_series= list(chain.from_iterable(liste_time_series))\n",
    "    liste_aux= list(chain.from_iterable(liste_aux))\n",
    "    liste_time_series_a= list(chain.from_iterable(liste_time_series_a))\n",
    "    liste_aux_a= list(chain.from_iterable(liste_aux_a))\n",
    "    \n",
    "    return np.array([[liste_time_series]]), np.array([liste_aux]),np.array(output),np.array([[liste_time_series_a]]),np.array([liste_aux_a]), np.array(output_a), mannschaftsliste.index(current_team)\n",
    "\n",
    "#---------------------SPIELTAG1\n",
    "\"\"\"\n",
    "input: team name, list of team, test data\n",
    "match day 1\n",
    "Here you have no TIMESEQUENCES --> create placeholder (-1)\n",
    "get auxdata completelynormal and at predict again the same input as at fit\n",
    "output: Team1,Team2, Prediction\n",
    "\n",
    "\"\"\"\n",
    "def spieltag1(teamname,mannschaftsliste,test):\n",
    "    current_team=similar(teamname,mannschaftsliste)\n",
    "    key= mannschaftsliste.index(current_team)\n",
    "    aux_data_test,mannschaften, output=auxilary_data_test(test,key)\n",
    "    aux_data= np.array(aux_data_test)\n",
    "    time= np.array([[[-1]*26]*5]*1) #np.full\n",
    "\n",
    "    out= output1(test,key)\n",
    "\n",
    "    return aux_data,time,out\n",
    "\"\"\"\n",
    "input: data, team\n",
    "Output conversion for the first day of play\n",
    "output: result \n",
    "\"\"\"\n",
    "def output1(test, mannschaft):\n",
    "    for i in test:\n",
    "        if mannschaft in i[-2:]:\n",
    "            out= i[-5:-2]\n",
    "            break\n",
    "    if out[0]==1:\n",
    "        return np.array([0])\n",
    "    elif out[1]==1:\n",
    "        return np.array([1])\n",
    "    else: \n",
    "        return np.array([2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Time2Vec has the following formula: \n",
    "           (1)     w_i*r+q_i, if i=0\n",
    "    t2v(r)[i]={\n",
    "           (2)    F(w_i*r+q_i), if 1<= i <=k\n",
    "\n",
    "    r= time-series\n",
    "(1) presents the non-periodic/linear feature of the time vector\n",
    "    rewritten = m_i*x+b_i (like a linear function)\n",
    "    w_i= matrix defining the slope of the time-series\n",
    "    q_i= matrix defining where time-series intersects with y-axis\n",
    "    ==> so a linear function\n",
    "(2) line presents periodic feature of time-vector\n",
    "    linear function this time packed into one function\n",
    "    sine function achieves best and most stable results\n",
    "    together: q shifts sine function along x-axis\n",
    "                w_i describes the wavelength of the sine function\n",
    "'''\n",
    "\n",
    "\"\"\"\n",
    "input: layer\n",
    "build the Time2Vec Vector\n",
    "\"\"\"\n",
    "class Time2Vector(Layer):\n",
    "    def __init__(self, seq_len, **kwargs):\n",
    "        super(Time2Vector, self).__init__()\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "    #Erstelle 4 Matrizen, 2 für w und 2 für q, für nicht-periodisch/periodisch\n",
    "    def build(self, input_shape):\n",
    "        self.w_linear = self.add_weight(name='w_linear',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.q_linear = self.add_weight(name='q_linear',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.w_periodic = self.add_weight(name='w_periodic',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "\n",
    "        self.q_periodic = self.add_weight(name='q_periodic',\n",
    "                                    shape=(int(self.seq_len),),\n",
    "                                    initializer='uniform',\n",
    "                                    trainable=True)\n",
    "    \n",
    "    #Eingabe hat folgende Form (batch_size,seq_len,26)\n",
    "    #batch_size: Anzahl der Sequenzen\n",
    "    #seq_len: Länge der einzelnen Sequenzen\n",
    "    #26: Anzahl der Statistiken\n",
    "    def call(self, x):\n",
    "        x = tf.math.reduce_mean(x, axis=-1)\n",
    "        #Linear Time Feature\n",
    "        t_linear = self.w_linear * x + self.q_linear \n",
    "        t_linear = tf.expand_dims(time_linear, axis=-1)\n",
    "        \n",
    "        #Periodisch Time Feature\n",
    "        t_periodic = tf.math.sin(tf.multiply(x, self.w_periodic) + self.q_periodic)\n",
    "        t_periodic = tf.expand_dims(t_periodic, axis=-1) \n",
    "        return tf.concat([t_linear, t_periodic], axis=-1) \n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'seq_len': self.seq_len})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "has 3 inputs (query, key, value)\n",
    "each input gets seperate linear transformation by passing it through individual dense\n",
    "#layers\n",
    "then calculates attention score/weights\n",
    "Aweights: determine how much focus is placed on individual #time series steps when #predicting a future outcome.\n",
    "time series steps is #calculated\n",
    "calculated by taking dot product of linearly transformed query/key inputs\n",
    "is\n",
    "then dividing by dimension size of previous shifts to #avoid exploding gradients\n",
    "avoid\n",
    "divided dot product then passes through softmax.\n",
    "last step: softmax matrix is multiplied by transformed v-matrix\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Build SingleHeadAttention\n",
    "\"\"\"\n",
    "class SingleHeadAttention(Layer):\n",
    "    def __init__(self, dim_k, dim_v):\n",
    "        super(SingleHeadAttention, self).__init__()\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        initializer= 'glorot_uniform'\n",
    "        self.query = Dense(self.dim_k, \n",
    "                           input_shape=input_shape, \n",
    "                           kernel_initializer=initializer, \n",
    "                           bias_initializer=initializer)\n",
    "\n",
    "        self.key = Dense(self.dim_k, \n",
    "                         input_shape=input_shape, \n",
    "                         kernel_initializer=initializer, \n",
    "                         bias_initializer=initializer)\n",
    "\n",
    "        self.value = Dense(self.dim_v, \n",
    "                           input_shape=input_shape, \n",
    "                           kernel_initializer=initializer, \n",
    "                           bias_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        q = self.query(inputs[0])\n",
    "        k = self.key(inputs[1])\n",
    "\n",
    "        attn_weights = tf.matmul(q, k, transpose_b=True)\n",
    "        attn_weights = tf.map_fn(lambda x: x/np.sqrt(self.dim_k), attn_weights)\n",
    "        attn_weights = tf.nn.softmax(attn_weights, axis=-1)\n",
    "\n",
    "        v = self.value(inputs[2])\n",
    "        attn_out = tf.matmul(attn_weights, v)\n",
    "        return attn_out    \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "\"\"\"\n",
    "MulitHeadAttention\n",
    "Concatenate the attention density of single head attention layers.\n",
    "then apply a nonlinear transformation with a dense layer\n",
    "\"\"\"\n",
    "class MultiHeadAttention(Layer):\n",
    "    def __init__(self, dim_k, dim_v, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.attn_heads = list()\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        initializer= 'glorot_uniform'\n",
    "        for n in range(self.n_heads):\n",
    "            self.attn_heads.append(SingleHeadAttention(self.dim_k, self.dim_v))  \n",
    "\n",
    "        self.linear = Dense(input_shape[0][-1], \n",
    "                            input_shape=input_shape, \n",
    "                            kernel_initializer=initializer, \n",
    "                            bias_initializer=initializer)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        attn = [self.attn_heads[i](inputs) for i in range(self.n_heads)]\n",
    "        concat_attn = tf.concat(attn, axis=-1)\n",
    "        multi_linear = self.linear(concat_attn)\n",
    "        return multi_linear   \n",
    "\n",
    "#############################################################################\n",
    "\n",
    "\"\"\"\n",
    "Single/multi head attention mechanism now summarize\n",
    "each encoder layer consists of self-attention and feedforward layer\n",
    "#feedforward consists of two dense layers with RELU activation in between\n",
    "'''Each sublayer is followed by a dropout layer, after the dropout a residual connection is\n",
    "is formed by adding the initial query input to both sublayer outputs.\n",
    "At the end of each sublayer, a normalization layer is placed after the \n",
    "addition to stabilize and accelerate the training process. \n",
    "speed up.\n",
    "Now we have a ready-to-use transformer layer that can be easily stacked,\n",
    "to improve the performance of a model. Since we do not need transformer decoder layers \n",
    "our implemented transformer architecture is very similar to the BERT [2] architecture. \n",
    "similar. However, the differences are the time embeddings and our transformer \n",
    "can process a 3-dimensional time series instead of a simple 2-dimensional sequence. \n",
    "process.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Build TransformerEncoder\n",
    "\"\"\"\n",
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, dim_k, dim_v, n_heads, ff_dim, dropout=0.1, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.dim_k = dim_k\n",
    "        self.dim_v = dim_v\n",
    "        self.n_heads = n_heads\n",
    "        self.ff_dim = ff_dim\n",
    "        self.attention_heads = list()\n",
    "        self.dropout_rate = dropout\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.attention_multi = MultiHeadAttention(self.dim_k, self.dim_v, self.n_heads)\n",
    "        self.attention_dropout = Dropout(self.dropout_rate)\n",
    "        self.attention_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)\n",
    "\n",
    "        self.ff_conv1D_1 = Conv1D(filters=self.ff_dim, kernel_size=1, activation='relu')\n",
    "        # input_shape[0]=(batch, seq_len, 7), input_shape[0][-1] = 7 \n",
    "        self.ff_conv1D_2 = Conv1D(filters=input_shape[0][-1], kernel_size=1) \n",
    "        self.ff_dropout = Dropout(self.dropout_rate)\n",
    "        self.ff_normalize = LayerNormalization(input_shape=input_shape, epsilon=1e-6)    \n",
    "\n",
    "    def call(self, inputs): # inputs = (in_seq, in_seq, in_seq)\n",
    "        attn_layer = self.attention_multi(inputs)\n",
    "        attn_layer = self.attention_dropout(attn_layer)\n",
    "        attn_layer = self.attention_normalize(inputs[0] + attn_layer)\n",
    "\n",
    "        ff_layer = self.ff_conv1D_1(attn_layer)\n",
    "        ff_layer = self.ff_conv1D_2(ff_layer)\n",
    "        ff_layer = self.ff_dropout(ff_layer)\n",
    "        ff_layer = self.ff_normalize(inputs[0] + ff_layer)\n",
    "        return ff_layer \n",
    "\n",
    "    def get_config(self): # Needed for saving and loading model with custom layer\n",
    "        config = super().get_config().copy()\n",
    "        config.update({'dim_k': self.dim_k,\n",
    "                       'dim_v': self.dim_v,\n",
    "                       'n_heads': self.n_heads,\n",
    "                       'ff_dim': self.ff_dim,\n",
    "                       'attention_heads': self.attention_heads,\n",
    "                       'dropout_rate': self.dropout_rate})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(seq_len,aux_data,dim_k,dim_v,n_heads,ff_dim):\n",
    "    '''Initialize time and transformer layers'''\n",
    "    time_embedding = Time2Vector(seq_len)\n",
    "    attn_layer1 = TransformerEncoder(dim_k, dim_v, n_heads, ff_dim)\n",
    "    attn_layer2 = TransformerEncoder(dim_k, dim_v, n_heads, ff_dim)\n",
    "    attn_layer3 = TransformerEncoder(dim_k, dim_v, n_heads, ff_dim)\n",
    "\n",
    "    '''Construct model'''\n",
    "    units= 128\n",
    "    in_seq = Input(shape=(seq_len, 26))\n",
    "    in_aux = Input(shape=(aux_data.shape[1],))\n",
    "    x = time_embedding(in_seq)\n",
    "    x = Concatenate(axis=-1)([in_seq, x])\n",
    "    x = attn_layer1((x, x, x))\n",
    "    x = attn_layer2((x, x, x))\n",
    "    x = attn_layer3((x, x, x))\n",
    "    x = GlobalAveragePooling1D(data_format='channels_first')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    \n",
    "    a = in_aux\n",
    "    a = Dense(units, activation='relu')(a)\n",
    "    x = Concatenate(axis=1)([x,a])\n",
    "    x = Dense(units, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    out = Dense(3, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[in_seq,in_aux], outputs=out)\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=tf.keras.optimizers.Adam(lr=5e-6, decay=1e-6), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "input: matchday, team, typ\n",
    "create data for the model\n",
    "output: data for model \n",
    "\"\"\"\n",
    "\n",
    "def model_data(spieltagsnummer,mannschaft,typ):\n",
    "    #---------------------EINGABE----------------------\n",
    "    spieltag=spieltagsnummer\n",
    "    teamname=mannschaft\n",
    "\n",
    "    #---------------------Hyperparameter----------------\n",
    "    dim_k = 128\n",
    "    dim_v = 128\n",
    "    n_heads = 32\n",
    "    ff_dim = 128\n",
    "    seq_len=5\n",
    "    epochen=50\n",
    "\n",
    "    #------------------- Normale Werte-------------------------------\n",
    "    #Trainings- oder Validationssatz verwenden\n",
    "    if typ == \"t\":\n",
    "        training, test, mannschaftsliste= getdataTraining(spieltag)\n",
    "    else:\n",
    "        training, test, mannschaftsliste= getdata(spieltag)\n",
    "    teamname_gegner,ort= getgegner(test,teamname,mannschaftsliste)\n",
    "\n",
    "    #----Spezialfälle----\n",
    "    if spieltag==1:    \n",
    "        aux,time,out= spieltag1(teamname,mannschaftsliste,test)\n",
    "        return aux, time,out\n",
    "        \n",
    "    if spieltag==2:\n",
    "        #Training\n",
    "        time2vec, aux_data, output,time2vec_a,aux_data_a,output_a,key= getspieltag2(training,test,mannschaftsliste,teamname)\n",
    "        output_data=out_data(output)\n",
    "        output_data_a=out_data(output_a)\n",
    "        #Test\n",
    "        time2vectest= time_sequence_test(training,test,key,spieltag)\n",
    "        aux_data_test,mannschaften,output_test=auxilary_data_test(test,key)\n",
    "        \n",
    "    #----Normalfall----\n",
    "    else:\n",
    "        #Datenreduktion, falls nötig\n",
    "        absteiger={0:[9,14],1:[7,8]}\n",
    "        aufsteiger={1:[18,19],2:[9,14]}\n",
    "        training_neu,spieltag_neu= data_auf_absteiger(training,mannschaftsliste,[teamname,teamname_gegner],spieltag,absteiger,aufsteiger)\n",
    "        if training_neu==\"KEY ERROR\":\n",
    "            return \"Fehler: Mannschaft befindet sich nicht in der Saison\"\n",
    "        \n",
    "        #Datenvorbereitung\n",
    "        if spieltag_neu==1:\n",
    "            aux,time,out= spieltag1(teamname,mannschaftsliste,test)\n",
    "            return aux, time,out\n",
    "        elif spieltag_neu==2:\n",
    "            #Training\n",
    "            time2vec, aux_data, output,time2vec_a,aux_data_a,output_a,key= getspieltag2(training,test,mannschaftsliste,teamname)\n",
    "            output_data=out_data(output)\n",
    "            output_data_a=out_data(output_a)\n",
    "            #Test\n",
    "            time2vectest= time_sequence_test(training,test,key,spieltag)\n",
    "            aux_data_test,mannschaften,output_test=auxilary_data_test(test,key)\n",
    "\n",
    "        else:\n",
    "            #Transformer Werte\n",
    "            #Home\n",
    "            time2vec,key, seq_len= time_sequence(training_neu,mannschaftsliste,teamname,spieltag_neu)\n",
    "            aux_data, output= auxilary_data(training_neu,key,spieltag_neu)\n",
    "            aux_data= np.array(aux_data[0])\n",
    "            output_data= out_data(output[0])\n",
    "\n",
    "            #Away\n",
    "            time2vec_a,key_a,seq_len= time_sequence(training_neu,mannschaftsliste,teamname_gegner,spieltag_neu)\n",
    "            aux_data_a,output_a= auxilary_data(training_neu,key_a,spieltag_neu)\n",
    "            aux_data_a=np.array(aux_data_a[0])\n",
    "            output_data_a= out_data(output_a[0])\n",
    "\n",
    "            #Test\n",
    "            time2vectest= time_sequence_test(training_neu,test,key,spieltag)\n",
    "            aux_data_test,mannschaften,output_test=auxilary_data_test(test,key)\n",
    "    \n",
    "            #Zeitreihen füllen, wenn diese zu klein sind\n",
    "    if time2vec[0].shape[0]<5:\n",
    "        \n",
    "        size= 5-time2vec[0].shape[0]\n",
    "        anzahl=time2vec.shape[0]\n",
    "        time2vec_neu= np.array(anzahl*[5*[[-1.0]*26]])\n",
    "        time2vec_a_neu= np.array(anzahl*[5*[[-1.0]*26]])\n",
    "        \n",
    "        for i in range(0,anzahl):\n",
    "            werte= time2vec[i]\n",
    "            werte_a= time2vec_a[i]\n",
    "            time2vec_neu[i]= np.concatenate((np.array(size*[[-1]*26]),werte),axis=0)\n",
    "            time2vec_a_neu[i]= np.concatenate((np.array(size*[[-1]*26]),werte_a),axis=0)\n",
    "            \n",
    "    else:\n",
    "        time2vec_neu= time2vec\n",
    "        time2vec_a_neu= time2vec_a\n",
    "    #Zusammenführung der Daten in richtiger Reihenfolge\n",
    "    if ort==\"home\":\n",
    "        time_all=np.concatenate((time2vec_neu,time2vec_a_neu),axis=0)\n",
    "        aux_all= np.concatenate((aux_data,aux_data_a),axis=0)\n",
    "        out_all= np.concatenate((output_data,output_data_a),axis=0)\n",
    "    else:\n",
    "        time_all=np.concatenate((time2vec_a_neu,time2vec_neu),axis=0)\n",
    "        aux_all= np.concatenate((aux_data_a,aux_data),axis=0)\n",
    "        out_all= np.concatenate((output_data_a,output_data),axis=0)\n",
    "        \n",
    "    return aux_all, time_all, out_all\n",
    "\n",
    "    #--------------------------- Transformer ausfuehren----------------------\n",
    "    model = create_model(seq_len,aux_data,dim_k,dim_v,n_heads,ff_dim)\n",
    "    \n",
    "    filepath= \"Transformer.hdf5\"\n",
    "    checkpoint_dir = os.path.dirname(filepath)\n",
    "\n",
    "    model.fit([time_all,aux_all],\n",
    "                        out_all, \n",
    "                        epochs=epochen, \n",
    "                       )\n",
    "\n",
    "    train_pred = model.predict([time2vectest,np.array(aux_data_test)]) \n",
    "    print(mannschaftsliste[int(mannschaften[0])],mannschaftsliste[int(mannschaften[1])])\n",
    "    print(train_pred)\n",
    "    if ort==\"home\":\n",
    "        return [teamname,teamname_gegner,train_pred,output_test]\n",
    "    else:\n",
    "        return [teamname_gegner,teamname,train_pred,output_test]\n",
    "#main(15,\"Leverkusen\")\n",
    "\n",
    "\"\"\"\n",
    "collect data for seasons and concat\n",
    "output: concat data\n",
    "\"\"\"\n",
    "def collect_data():\n",
    "    teams= get_mannschaftenTraining()\n",
    "    saison1= teams[:18]\n",
    "    saison2= get_mannschaftenTraining()\n",
    "    saison3= get_mannschaftenTraining()\n",
    "    del saison2[9]\n",
    "    del saison2[13]\n",
    "    del saison3[7]\n",
    "    del saison3[7]\n",
    "    liste_aux=[]\n",
    "    liste_time=[]\n",
    "    liste_out=[]\n",
    "    \n",
    "    #1. Saison \n",
    "    for i in range(1,35):\n",
    "        for j in saison1:\n",
    "            a,t,o=model_data(i,j,\"t\")\n",
    "            liste_aux.append(a)\n",
    "            liste_time.append(t)\n",
    "            liste_out.append(o)\n",
    "    #2. Saison \n",
    "    for i in range(35,69):\n",
    "        for j in saison2:\n",
    "            a,t,o=model_data(i,j,\"t\")\n",
    "            liste_aux.append(a)\n",
    "            liste_time.append(t)\n",
    "            liste_out.append(o)\n",
    "    #3.Saison\n",
    "    for i in range(69,103):\n",
    "        for j in saison3:\n",
    "            a,t,o=model_data(i,j,\"t\")\n",
    "            liste_aux.append(a)\n",
    "            liste_time.append(t)\n",
    "            liste_out.append(o)\n",
    "    \n",
    "    #Concat der einzelnen Datentypen(Aux,Zeit,Ausgabe)\n",
    "    a= liste_aux[0]\n",
    "    for i in liste_aux[1:]:\n",
    "        a= np.concatenate((a,i),axis=0)\n",
    "    \n",
    "\n",
    "    t= liste_time[0]\n",
    "    for i in liste_time[1:]:\n",
    "        t= np.concatenate((t,i),axis=0)\n",
    "    \n",
    "\n",
    "    o= liste_out[0]\n",
    "    for i in liste_out[1:]:\n",
    "        o= np.concatenate((o,i),axis=0)\n",
    "    \n",
    "    return a,t,o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "fit the model and save it\n",
    "ouput: trained model\n",
    "\"\"\"\n",
    "def fit_with_vali_as_train():\n",
    "    #Training\n",
    "    aux_t,time_t,out_t= collect_data()\n",
    "    #Validierung\n",
    "    aux_v,time_v,out_v= collect_data_V()\n",
    "    \n",
    "    aux_all = np.concatenate((aux_t,aux_v),axis=0)\n",
    "    time_all= np.concatenate((time_t,time_v),axis=0)\n",
    "    out_all= np.concatenate((out_t,out_v),axis=0)\n",
    "\n",
    "    dim_k = 256#128\n",
    "    dim_v = 256#128\n",
    "    n_heads = 12#32\n",
    "    ff_dim = 256#128\n",
    "    seq_len=5\n",
    "    epochen=25\n",
    "    \n",
    "    model = create_model(seq_len,aux_t,dim_k,dim_v,n_heads,ff_dim)\n",
    "    model.fit([time_all,aux_all],out_all, epochs=epochen)\n",
    "    model.save('Transformer4Saisons')\n",
    "#fit_with_vali_as_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Gladbach',\n",
       " 'Fortuna Düsseldorf',\n",
       " array([0.7059262 , 0.23751928, 0.05655461], dtype=float32),\n",
       " array([1., 0., 0.])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "input: matchday, team\n",
    "Get data for prediction and run it\n",
    "Load model and predict on it\n",
    "ouput: prediction\n",
    "\"\"\"\n",
    "def getPredictData(spieltag, mannschaft):\n",
    "    spieltag=spieltag\n",
    "    teamname=mannschaft\n",
    "    training, test, mannschaftsliste= getdata(spieltag)\n",
    "    teamname_gegner,ort= getgegner(test,teamname,mannschaftsliste)    \n",
    "\n",
    "    \n",
    "    #Sonedrfall\n",
    "    if spieltag==1:\n",
    "        aux,time,out= spieltag1(teamname,mannschaftsliste,test)\n",
    "        new_model = tf.keras.models.load_model('Transformer6Saisons')\n",
    "        output= new_model.predict([time,aux])[0]\n",
    "\n",
    "        teamname_gegner,ort= getgegner(test,teamname,mannschaftsliste)\n",
    "        if out==[0]:\n",
    "            out=[1,0,0]\n",
    "        elif out==[1]:\n",
    "            out=[0,1,0]\n",
    "        else:\n",
    "            out=[0,0,1]\n",
    "        if ort==\"home\":\n",
    "            return [teamname,teamname_gegner,output,out]\n",
    "        else:\n",
    "            return [teamname_gegner,teamname,output,out]\n",
    "        \n",
    "    #Hier wird nur der Key geholt    \n",
    "    elif spieltag>2:\n",
    "        time2vec,key, seq_len= time_sequence(training,mannschaftsliste,teamname,spieltag)\n",
    "    else: \n",
    "        time2vec, aux_data, output,time2vec_a,aux_data_a,output_a,key= getspieltag2(training,test,mannschaftsliste,teamname)\n",
    "\n",
    "    #Daten holen\n",
    "\n",
    "    time2vectest= time_sequence_test(training,test,key,spieltag)\n",
    "    aux_data_test,mannschaften,output_test=auxilary_data_test(test,key)\n",
    "    aux_data_test=np.array(aux_data_test)\n",
    "    if time2vec[0].shape[0]<5:\n",
    "        \n",
    "        size= 5-time2vectest[0].shape[0]\n",
    "        anzahl=time2vectest.shape[0]\n",
    "        time2vec_neu= np.array(anzahl*[5*[[-1.0]*26]])\n",
    "        time2vec_neu[0]= np.concatenate((np.array(size*[[-1]*26]),time2vectest[0]),axis=0)\n",
    "\n",
    "    else:\n",
    "        time2vec_neu= time2vectest\n",
    "    #Modell laden und vorhersagen\n",
    "    new_model = tf.keras.models.load_model('Transformer4Saisons')\n",
    "    output= new_model.predict([time2vec_neu,aux_data_test])[0]   \n",
    "    #Ausgabe\n",
    "    if ort==\"home\":\n",
    "        return [teamname,teamname_gegner,output,output_test]\n",
    "    else:\n",
    "        return [teamname_gegner,teamname,output,output_test]\n",
    "    \n",
    "getPredictData(10, \"Gladbach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
